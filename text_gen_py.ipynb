{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "I-MO8xZCj08r",
        "outputId": "c9739077-8930-421d-dc8e-387988f618e3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'sample_text.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c8c0d9db7bbf>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mchain_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mnum_generated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mgenerated_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_generated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-c8c0d9db7bbf>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(filename, start_words, chain_length, num_generated)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_words\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_generated\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_text_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mchain_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-c8c0d9db7bbf>\u001b[0m in \u001b[0;36mread_text_from_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_text_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"\"\"Reads text from the specified file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_text.txt'"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def read_text_from_file(filename: str) -> str:\n",
        "    \"\"\"Reads text from the specified file.\"\"\"\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def preprocess_text(text: str) -> list:\n",
        "    \"\"\"Preprocesses the text by splitting it into words.\"\"\"\n",
        "    return text.split()\n",
        "\n",
        "def build_markov_chain(words: list, chain_length: int, start_prefix: str = '<START>') -> dict:\n",
        "    \"\"\"Builds a Markov Chain based on the given words, chain length, and start prefix.\"\"\"\n",
        "    markov_chain = {}\n",
        "    current_words = tuple([start_prefix] * (chain_length - 1) + [words[0]])\n",
        "    for word in words[1:]:\n",
        "        key = current_words\n",
        "        value = word\n",
        "        markov_chain.setdefault(key, []).append(value)\n",
        "        current_words = current_words[1:] + (word,)\n",
        "    print(markov_chain)\n",
        "    return markov_chain\n",
        "\n",
        "def generate_sentence(markov_chain: dict, start_words: list, num_generated: int) -> str:\n",
        "    \"\"\"Generates a sentence using the given Markov Chain, start words, and number of words to generate.\"\"\"\n",
        "    sentence = start_words.copy()\n",
        "    current_words = tuple(start_words)\n",
        "\n",
        "    while len(sentence) < num_generated:\n",
        "        next_word = random.choice(markov_chain.get(current_words, ['']))\n",
        "        sentence.append(next_word)\n",
        "        current_words = current_words[1:] + (next_word,)\n",
        "\n",
        "        if not next_word:  # If next_word is empty, i.e., no more words to generate\n",
        "            break\n",
        "\n",
        "    return ' '.join(sentence)\n",
        "\n",
        "def generate(filename: str, start_words: list[str], chain_length: int, num_generated: int) -> str:\n",
        "    text = read_text_from_file(filename)\n",
        "    words = preprocess_text(text)\n",
        "    if len(words) < chain_length + 1:\n",
        "        raise ValueError(\"Text file is too short for the given chain length\")\n",
        "\n",
        "    if len(start_words) < chain_length:\n",
        "        start_words = ['<START>'] * (chain_length - len(start_words)) + start_words\n",
        "\n",
        "    markov_chain = build_markov_chain(words, chain_length)\n",
        "    return generate_sentence(markov_chain, start_words, num_generated)\n",
        "\n",
        "# Example usage\n",
        "filename = 'sample_text.txt'\n",
        "start_words = ['It', 'was']  # Only one start word provided\n",
        "chain_length = 2\n",
        "num_generated = 5\n",
        "generated_sentence = generate(filename, start_words, chain_length, num_generated)\n",
        "print(generated_sentence)"
      ]
    }
  ]
}